# Applied Accelerated ML - Course Layout

## Week 1

- AI system hardware: CPU, RAM, GPU, interconnects, storage, network controller.
- AI accelerators (GPUs).
- System software: OS, virtualization, cloud.

## Week 2

- Containers and IDE (Jupyter demo).
- Scheduling and resource management.
- DeepOps: Kubernetes for AI services.

## Week 3

- DeepOps (contd).
- Design principles for high performance AI compute clusters.
- Implementation details for AI compute clusters.

## Week 4

- Accelerated deep learning frameworks: PyTorch (lecture).
- PyTorch (contd) with demo.
- Accelerated PyTorch.

## Week 5

- Accelerated deep learning frameworks: TensorFlow (lecture).
- TensorFlow (contd) with demo.
- Accelerated TensorFlow.

## Week 6

- Optimizing training: automated mixed precision.
- Transfer learning.

## Week 7

- Distributed AI computing: multi-GPU and multi-node (MPI, NCCL, RDMA).
- Horovod (lecture + demo).

## Week 8

- Challenges in distributed training convergence.
- Accelerating deployment fundamentals.

## Week 9

- Accelerating inference in PyTorch and TensorFlow.
- Accelerated data analytics.
- Accelerated machine learning.

## Week 10

- Scale out with DASK.
- GPU accelerated crossfiltering.
- Accelerated ETL with SPARK.

## Week 11

- Applied AI: smart city intelligent video analytics.

## Week 12

- Applied AI: healthcare (federated learning, AI-assisted annotation).
